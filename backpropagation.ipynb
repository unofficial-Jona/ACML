{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "from typing import List, Union, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.identity(8)\n",
    "y = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z: float) -> float:\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def quadratic_loss(predictions: np.ndarray, actuals: np.ndarray) -> np.ndarray:\n",
    "    norms = np.apply_along_axis(np.linalg.norm, 0, predictions-actuals)\n",
    "    return 0.5*np.apply_along_axis(np.power, 0, norms, 2)\n",
    "    # return 0.5*np.apply_along_axis(np.power, 0, norms, {'x2': 2})\n",
    "\n",
    "def cost_function(loss_function: Callable, predictions: np.ndarray, actuals: np.ndarray, weigths: np.ndarray, decay_parameter: float) -> float:\n",
    "    avg_loss: float = np.mean(loss_function(predictions, actuals))\n",
    "    regularization: float = 0.5 * decay_parameter * sum(np.power(weights, 2))\n",
    "    return avg_loss+regularization\n",
    "\n",
    "class Layer:\n",
    "\n",
    "    # declaration of instance variables\n",
    "    weigths: np.ndarray\n",
    "    has_bias: bool\n",
    "\n",
    "    def __init__(self, num_nodes: int, num_nodes_n1: int, include_bias: bool = True, epsilon: float = 0.1) -> None:\n",
    "        self.weights = np.random.normal(loc=0, scale=np.power(epsilon,2), size=(num_nodes_n1, np.add(num_nodes, include_bias)))\n",
    "        self.has_bias = include_bias\n",
    "    \n",
    "    def print_weights(self) -> None:\n",
    "        print(self.weights)\n",
    "\n",
    "\n",
    "class Network:\n",
    "\n",
    "    # declaration of instance variables\n",
    "    layers: List[Layer]\n",
    "    weights: List[np.ndarray]\n",
    "\n",
    "    def __init__(self, num_nodes: List[int], include_biases: List[bool]) -> None:\n",
    "        # num_nodes is a list of number of nodes for all layers not counting the bias node\n",
    "        # TO-DO: code won't work if include_biases != [True, True, False], see prop_forward\n",
    "        assert (include_biases == [True, True, False]), 'error when initializing Network class: include_bias parameter not available'\n",
    "\n",
    "        self.layers = [Layer(num_nodes[i], num_nodes[i+1], include_biases[i]) for i in range(len(num_nodes)-1)]\n",
    "        self.layers.append(Layer(num_nodes[-1], 0, include_biases[-1]))\n",
    "        self.weights = self.get_weights(form='list')\n",
    "\n",
    "    def get_weights(self, form: str = 'vector') -> Union[List[np.ndarray], np.ndarray]:\n",
    "        assert (form in ['vector', 'list']), 'Error in get_weights function: form parameter ill-defined'\n",
    "\n",
    "        if form == 'vector':\n",
    "            # returns one np.ndarray with all weights of all layers\n",
    "            weigth_vector = []\n",
    "            for layer in self.layers:\n",
    "                weigth_vector.append(layer.weights)\n",
    "            return np.asarray(weigth_vector)\n",
    "        elif form == 'list':\n",
    "            # returns a list, where list[i] stores the weights between layer i-1 and layer i\n",
    "            list_of_weights: List[np.ndarray] = []\n",
    "            for layer in self.layers:\n",
    "                list_of_weights.append(layer.weights)\n",
    "            return list_of_weights\n",
    "\n",
    "    def print_weights(self) -> None:\n",
    "        print('Printing weights of network:')\n",
    "        for index, layer in enumerate(self.layers):\n",
    "            print(f'Layer {index+1}')\n",
    "            layer.print_weights()\n",
    "\n",
    "    def prop_forward(self, features: np.ndarray) -> List[np.ndarray]:\n",
    "        # returns a list, where list[i] stores the activations for neurons in layer i+1\n",
    "        # the activation of a bias node (should the layer have one) is given by the first value in the array and is always =1\n",
    "        # TO-DO: right now it is hard coded that input layer & hidden layer have a bias node, but output layer has not\n",
    "        z_2 = np.matmul(self.weights[0], np.append(1, features))\n",
    "        a_2 = np.apply_along_axis(sigmoid, 0, z_2)\n",
    "        z_3 = np.matmul(self.weights[1], np.append(1, a_2))\n",
    "        a_3 = np.apply_along_axis(sigmoid, 0, z_3)\n",
    "        # print(a_3)\n",
    "        return [np.append(1, features), np.append(1, a_2), a_3]\n",
    "\n",
    "    def print_activations(self, features: np.ndarray) -> None:\n",
    "        print(f'Printing activations for input: {features}')\n",
    "        for index, array in enumerate(self.prop_forward(features)):\n",
    "            print(f'Layer {index+1}: {array}')\n",
    "\n",
    "    def get_deltas(self, X: np.ndarray, y: np.ndarray, activations: List[np.ndarray]=None) -> List[np.ndarray]:\n",
    "        # TO-DO: adapt code to accept different cost functions\n",
    "        # Right now: hard coded to use quadratic loss\n",
    "        if activations == None:\n",
    "            activations = self.prop_forward(X)\n",
    "        weights = self.weights\n",
    "        deltas = []\n",
    "\n",
    "        # z = activations[-1] * weights[-2]\n",
    "\n",
    "        deltas_output = -np.multiply((y-activations[-1]), np.apply_along_axis(sigmoid_derivative, 0, np.dot(weights[1], activations[-2])))\n",
    "        #  print('mat_mul: ', (y-activations[-1]), 'z: ', np.dot(weights[1], activations[-2]))\n",
    "        deltas.insert(0, deltas_output)\n",
    "\n",
    "        # print('shape: ', np.transpose(weights[0]).shape, deltas[0].shape, np.matmul(weights[0][:, 1:], deltas[0]))\n",
    "\n",
    "        mat_mul = np.matmul(weights[1].T, deltas[0].reshape((8,1)))\n",
    "        z = np.matmul(weights[0], activations[0])\n",
    "        \n",
    "        # print('mat_mul: ', mat_mul, 'z: ', z)\n",
    "        \n",
    "        deltas_2 = -np.multiply(mat_mul[1:], np.apply_along_axis(sigmoid_derivative, 0, z))\n",
    "        \n",
    "        # print(deltas_2)\n",
    "        \n",
    "        deltas.insert(0, deltas_2)\n",
    "        '''\n",
    "        for i in range(len(activations)-2):\n",
    "            \n",
    "            \n",
    "            \n",
    "            delta = np.multiply(\n",
    "                np.matmul(np.transpose(weights[-(i+2)]), deltas[-(i+1)]), np.apply_along_axis(sigmoid_derivative, 0, np.dot(weights[1], activations[-2])))\n",
    "            \n",
    "            \n",
    "            # remove 'bias delta', as activation of bias cannot be changed\n",
    "        \n",
    "            deltas.insert(0, delta[1:])\n",
    "            '''\n",
    "        print(deltas)\n",
    "        return deltas\n",
    "\n",
    "    def partial_derivatives(self, X: np.ndarray, y: np.ndarray, verbose: bool =False) -> List[np.ndarray]:\n",
    "        activations = self.prop_forward(X)\n",
    "        deltas = self.get_deltas(X, y, activations)\n",
    "        partial_derivatives = []\n",
    "        for index in range(len(deltas)):\n",
    "            if verbose:\n",
    "                # for testing/debugging purposes\n",
    "                print(f'Layer {index+1}: dimension deltas {index+2} {deltas[index].shape}, dimension activations {index+1} {activations[index].shape}')\n",
    "                print(f'activations: {activations[index]}')\n",
    "                print(f'deltas: {deltas[index]}')\n",
    "            partial = np.outer(deltas[index], np.transpose(activations[index]))\n",
    "            if verbose:\n",
    "                # deltas should be equal to partial derivatives of the bias node\n",
    "                print(f'Partial of bias: {partial.shape}')\n",
    "            partial_derivatives.append(partial)\n",
    "        return partial_derivatives\n",
    "\n",
    "\n",
    "    def update_weights(self, big_delta: List[np.ndarray], regularization_parameter: float, learning_rate: float=0.01) -> None:\n",
    "        for num_layer in range(len(self.weights)):\n",
    "            self.weights[num_layer] = self.weights[num_layer]-learning_rate*(big_delta[num_layer] + regularization_parameter*self.weights[num_layer])\n",
    "\n",
    "    def gradient_descent(self, X_train: np.ndarray, y_train: np.ndarray, regularization_parameter: float, learning_rate: float=0.01) -> None:\n",
    "        # This is only for a single example? \n",
    "        # --> create batch gradient descent\n",
    "        big_delta: List[np.ndarray] = [] \n",
    "        for index in range(len(self.weights)):\n",
    "            big_delta.append(np.zeros(self.weights[index].shape))\n",
    "        for num_instance in range(X_train.shape[0]):\n",
    "            partials = self.partial_derivatives(X[num_instance], y[num_instance])\n",
    "            for num_layer in range(len(self.layers)-1):\n",
    "                \n",
    "                print('num_layer: ', num_layer, 'big_delta: ', big_delta[num_layer], 'partials: ', partials[num_layer])\n",
    "                \n",
    "                big_delta[num_layer] = big_delta[num_layer]+partials[num_layer]\n",
    "        for num_layer in range(len(self.layers)):\n",
    "            big_delta[num_layer] = (1/X_train.shape[0])*big_delta[num_layer]\n",
    "        self.update_weights(big_delta, regularization_parameter, learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    def train_network(self, n_iter: int, X_train: np.ndarray, y_train: np.ndarray, regul_param: float, learning_rate: float=0.01) -> None:\n",
    "        # TO-DO: print/plot loss after each iteration \n",
    "        \n",
    "        # calculate activation\n",
    "        # loss based on activation\n",
    "        costs = [[], []]\n",
    "        for iter in range(n_iter):\n",
    "            \n",
    "            temp_costs = []            \n",
    "            \n",
    "            for instance in X_train:\n",
    "                act_3 = self.prop_forward(instance)[2].reshape((8,1))\n",
    "                weights_3 = self.weights[-2]\n",
    "                # print('shape act_3: ', act_3.shape, ' shape weights_3: ', weights_3.shape)\n",
    "                cos = cost_function(quadratic_loss, act_3, instance, weights_3, 1)\n",
    "                temp_costs.append(cos)\n",
    "                # print('predictions: ', act_3)\n",
    "            costs[0].append(iter)\n",
    "            costs[1].append(np.mean(temp_costs))\n",
    "            self.gradient_descent(X_train, y_train, regularization_parameter=regul_param, learning_rate=learning_rate)\n",
    "            \n",
    "        \n",
    "        \n",
    "        plt.plot(costs[0], costs[1])\n",
    "        return None\n",
    "\n",
    "\n",
    "test_network = Network([8,3,8], [True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_mul:  [ 0.50114193 -0.50217193 -0.49777153 -0.49889942 -0.49969396 -0.50236015\n",
      " -0.49519601 -0.49928746] z:  [-0.00456773  0.00868777 -0.00891395 -0.00440234 -0.00122416  0.00944065\n",
      " -0.01921653 -0.00285017]\n",
      "mat_mul:  [[-0.00302604]\n",
      " [-0.0016963 ]\n",
      " [ 0.00040377]\n",
      " [ 0.00397432]] z:  [0.03629225 0.00636748 0.00268167]\n",
      "[array([[ 0.00042394,  0.00042407,  0.00042408],\n",
      "       [-0.00010091, -0.00010094, -0.00010094],\n",
      "       [-0.00099325, -0.00099357, -0.00099358]]), array([-0.12528483,  0.12554061,  0.12444041,  0.12472425,  0.12492344,\n",
      "        0.12558724,  0.12378758,  0.12482161])]\n",
      "num_layer:  0 big_delta:  [[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]] partials:  [[ 0.00042394  0.00042394  0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00042407  0.00042407  0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00042408  0.00042408  0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.00010091 -0.00010091 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00010094 -0.00010094 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00010094 -0.00010094 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00099325 -0.00099325 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00099357 -0.00099357 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00099358 -0.00099358 -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,9) (9,9) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/5g0l_qvd0fs6sjcr166g3y4m0000gn/T/ipykernel_3392/929356771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregul_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yh/5g0l_qvd0fs6sjcr166g3y4m0000gn/T/ipykernel_3392/3523473979.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, n_iter, X_train, y_train, regul_param, learning_rate)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mcosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_costs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_parameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregul_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yh/5g0l_qvd0fs6sjcr166g3y4m0000gn/T/ipykernel_3392/3523473979.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self, X_train, y_train, regularization_parameter, learning_rate)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_layer: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'big_delta: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'partials: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mbig_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbig_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnum_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mbig_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbig_delta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,9) (9,9) "
     ]
    }
   ],
   "source": [
    "test_network.train_network(10000, X, y, regul_param=0.1, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_mul:  [ 0.49799068 -0.49508336 -0.49910857 -0.50165805 -0.49952519 -0.49939136\n",
      " -0.49864113 -0.50051377] z:  [ 0.00803734 -0.01966719 -0.00356571  0.00663221 -0.00189925 -0.00243456\n",
      " -0.00543549  0.00205507]\n",
      "mat_mul:  [[-4.86375489e-04]\n",
      " [-3.86207036e-03]\n",
      " [-3.22409365e-03]\n",
      " [ 6.00365745e-06]] z:  [-0.01207075 -0.00675809  0.02142671]\n",
      "[array([[ 9.65482422e-04,  9.65506566e-04,  9.65406781e-04],\n",
      "       [ 8.05994053e-04,  8.06014209e-04,  8.05930907e-04],\n",
      "       [-1.50085969e-06, -1.50089722e-06, -1.50074211e-06]]), array([-0.12449566,  0.12375887,  0.12477675,  0.12541313,  0.12488118,\n",
      "        0.12484766,  0.12465936,  0.12512831])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "deltas: [[ 9.65482422e-04  9.65506566e-04  9.65406781e-04]\n",
      " [ 8.05994053e-04  8.06014209e-04  8.05930907e-04]\n",
      " [-1.50085969e-06 -1.50089722e-06 -1.50074211e-06]]\n",
      "Partial of bias: [ 9.65482422e-04  9.65506566e-04  9.65406781e-04  8.05994053e-04\n",
      "  8.06014209e-04  8.05930907e-04 -1.50085969e-06 -1.50089722e-06\n",
      " -1.50074211e-06]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.49698235 0.49831048 0.50535647]\n",
      "deltas: [-0.12449566  0.12375887  0.12477675  0.12541313  0.12488118  0.12484766\n",
      "  0.12465936  0.12512831]\n",
      "Partial of bias: [-0.06187214  0.06150598  0.06201184  0.06232811  0.06206374  0.06204708\n",
      "  0.0619535   0.06218656]\n",
      "[[ 9.65482422e-04  9.65482422e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 9.65506566e-04  9.65506566e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 9.65406781e-04  9.65406781e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.05994053e-04  8.05994053e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.06014209e-04  8.06014209e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.05930907e-04  8.05930907e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-1.50085969e-06 -1.50085969e-06 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]\n",
      " [-1.50089722e-06 -1.50089722e-06 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]\n",
      " [-1.50074211e-06 -1.50074211e-06 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]]\n",
      "mat_mul:  [-0.50197928  0.50495095 -0.49910848 -0.50164323 -0.49951331 -0.49938571\n",
      " -0.49864876 -0.50049873] z:  [ 0.00791716 -0.01980446 -0.00356608  0.00657293 -0.00194675 -0.00245715\n",
      " -0.00540497  0.00199493]\n",
      "mat_mul:  [[0.00013604]\n",
      " [0.00051787]\n",
      " [0.00082625]\n",
      " [0.0041777 ]] z:  [0.00290888 0.00252798 0.00077786]\n",
      "[array([[-0.00012947, -0.00012947, -0.00012947],\n",
      "       [-0.00020656, -0.00020656, -0.00020656],\n",
      "       [-0.00104442, -0.00104442, -0.00104443]]), array([ 0.12549285, -0.12622536,  0.12477672,  0.12540945,  0.12487821,\n",
      "        0.12484624,  0.12466128,  0.12512456])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "deltas: [[-0.00012947 -0.00012947 -0.00012947]\n",
      " [-0.00020656 -0.00020656 -0.00020656]\n",
      " [-0.00104442 -0.00104442 -0.00104443]]\n",
      "Partial of bias: [-0. -0. -0. -0. -0. -0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.50072722 0.50063199 0.50019447]\n",
      "deltas: [ 0.12549285 -0.12622536  0.12477672  0.12540945  0.12487821  0.12484624\n",
      "  0.12466128  0.12512456]\n",
      "Partial of bias: [ 0.06283769 -0.06320447  0.0624791   0.06279593  0.06252992  0.06251391\n",
      "  0.0624213   0.06265327]\n",
      "[[-0.00012947 -0.         -0.00012947 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00012947 -0.         -0.00012947 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00012947 -0.         -0.00012947 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00020656 -0.         -0.00020656 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00020656 -0.         -0.00020656 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00020656 -0.         -0.00020656 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00104442 -0.         -0.00104442 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00104442 -0.         -0.00104442 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00104443 -0.         -0.00104443 -0.         -0.         -0.\n",
      "  -0.         -0.         -0.        ]]\n",
      "mat_mul:  [-0.50197026 -0.49507609  0.50090286 -0.50164585 -0.49952561 -0.49940049\n",
      " -0.49864946 -0.50049255] z:  [ 0.00788109 -0.01969627 -0.00361143  0.00658341 -0.00189757 -0.00239802\n",
      " -0.00540216  0.00197021]\n",
      "mat_mul:  [[ 0.00103949]\n",
      " [-0.00590825]\n",
      " [-0.00293515]\n",
      " [ 0.0044538 ]] z:  [-0.01904    -0.00136204 -0.00697863]\n",
      "[array([[ 0.00147693,  0.00147706,  0.00147705],\n",
      "       [ 0.00073372,  0.00073379,  0.00073378],\n",
      "       [-0.00111335, -0.00111345, -0.00111344]]), array([ 0.12549062,  0.12375702, -0.12522531,  0.1254101 ,  0.12488129,\n",
      "        0.12484994,  0.12466146,  0.12512302])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "deltas: [[ 0.00147693  0.00147706  0.00147705]\n",
      " [ 0.00073372  0.00073379  0.00073378]\n",
      " [-0.00111335 -0.00111345 -0.00111344]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.49524014 0.49965949 0.49825535]\n",
      "deltas: [ 0.12549062  0.12375702 -0.12522531  0.1254101   0.12488129  0.12484994\n",
      "  0.12466146  0.12512302]\n",
      "Partial of bias: [ 0.06214799  0.06128944 -0.0620166   0.06210812  0.06184623  0.0618307\n",
      "  0.06173736  0.06196594]\n",
      "[[ 0.00147693  0.          0.          0.00147693  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00147706  0.          0.          0.00147706  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00147705  0.          0.          0.00147705  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00073372  0.          0.          0.00073372  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00073379  0.          0.          0.00073379  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00073378  0.          0.          0.00073378  0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.00111335 -0.         -0.         -0.00111335 -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00111345 -0.         -0.         -0.00111345 -0.         -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00111344 -0.         -0.         -0.00111344 -0.         -0.\n",
      "  -0.         -0.         -0.        ]]\n",
      "mat_mul:  [-0.50199547 -0.49508607 -0.49909598  0.49834003 -0.49955262 -0.49939348\n",
      " -0.49863456 -0.50049812] z:  [ 0.00798192 -0.01965633 -0.00361608  0.0066399  -0.00178952 -0.0024261\n",
      " -0.00546177  0.00199248]\n",
      "mat_mul:  [[-0.00193202]\n",
      " [-0.00276875]\n",
      " [-0.00410321]\n",
      " [ 0.00335333]] z:  [-0.02937046  0.0057888   0.0115188 ]\n",
      "[array([[ 0.00069204,  0.00069218,  0.00069217],\n",
      "       [ 0.00102558,  0.0010258 ,  0.00102577],\n",
      "       [-0.00083815, -0.00083833, -0.0008383 ]]), array([ 0.12549687,  0.12375956,  0.12477359, -0.12458363,  0.12488805,\n",
      "        0.12484819,  0.12465771,  0.12512441])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "deltas: [[ 0.00069204  0.00069218  0.00069217]\n",
      " [ 0.00102558  0.0010258   0.00102577]\n",
      " [-0.00083815 -0.00083833 -0.0008383 ]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.49265791 0.5014472  0.50287967]\n",
      "deltas: [ 0.12549687  0.12375956  0.12477359 -0.12458363  0.12488805  0.12484819\n",
      "  0.12465771  0.12512441]\n",
      "Partial of bias: [ 0.06182703  0.06097113  0.0614707  -0.06137711  0.06152709  0.06150745\n",
      "  0.06141361  0.06164353]\n",
      "[[ 0.00069204  0.          0.          0.          0.00069204  0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00069218  0.          0.          0.          0.00069218  0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00069217  0.          0.          0.          0.00069217  0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00102558  0.          0.          0.          0.00102558  0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.0010258   0.          0.          0.          0.0010258   0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.00102577  0.          0.          0.          0.00102577  0.\n",
      "   0.          0.          0.        ]\n",
      " [-0.00083815 -0.         -0.         -0.         -0.00083815 -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.00083833 -0.         -0.         -0.         -0.00083833 -0.\n",
      "  -0.         -0.         -0.        ]\n",
      " [-0.0008383  -0.         -0.         -0.         -0.0008383  -0.\n",
      "  -0.         -0.         -0.        ]]\n",
      "mat_mul:  [-0.50199797 -0.49508538 -0.49911496 -0.50164699  0.5005125  -0.49940131\n",
      " -0.49865808 -0.50051988] z:  [ 0.00799191 -0.01965912 -0.00354017  0.00658797 -0.00205001 -0.00239477\n",
      " -0.0053677   0.0020795 ]\n",
      "mat_mul:  [[ 0.00106655]\n",
      " [-0.00032027]\n",
      " [-0.00860788]\n",
      " [ 0.00367412]] z:  [ 0.00048521 -0.02422765  0.01238009]\n",
      "[array([[ 8.00667639e-05,  8.00550204e-05,  8.00637008e-05],\n",
      "       [ 2.15197013e-03,  2.15165450e-03,  2.15188781e-03],\n",
      "       [-9.18530769e-04, -9.18396047e-04, -9.18495629e-04]]), array([ 0.12549749,  0.12375939,  0.12477835,  0.12541039, -0.12512799,\n",
      "        0.12485015,  0.12466362,  0.12512983])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "deltas: [[ 8.00667639e-05  8.00550204e-05  8.00637008e-05]\n",
      " [ 2.15197013e-03  2.15165450e-03  2.15188781e-03]\n",
      " [-9.18530769e-04 -9.18396047e-04 -9.18495629e-04]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.5001213  0.49394338 0.50309498]\n",
      "deltas: [ 0.12549749  0.12375939  0.12477835  0.12541039 -0.12512799  0.12485015\n",
      "  0.12466362  0.12512983]\n",
      "Partial of bias: [ 0.06276397  0.06189471  0.06240431  0.06272041 -0.06257918  0.06244022\n",
      "  0.06234693  0.0625801 ]\n",
      "[[ 8.00667639e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.00667639e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.00550204e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.00550204e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.00637008e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  8.00637008e-05  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.15197013e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.15197013e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.15165450e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.15165450e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 2.15188781e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.15188781e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-9.18530769e-04 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -9.18530769e-04 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]\n",
      " [-9.18396047e-04 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -9.18396047e-04 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]\n",
      " [-9.18495629e-04 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -9.18495629e-04 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00]]\n",
      "mat_mul:  [-0.5019784  -0.49508699 -0.49909762 -0.50164946 -0.49952613  0.5005968\n",
      " -0.49864858 -0.50049761] z:  [ 0.00791363 -0.01965268 -0.00360953  0.00659785 -0.00189549 -0.0023872\n",
      " -0.00540568  0.00199046]\n",
      "mat_mul:  [[-0.00326923]\n",
      " [-0.00237759]\n",
      " [-0.00083929]\n",
      " [ 0.00688145]] z:  [-0.02273936 -0.00572487 -0.00150794]\n",
      "[array([[ 0.00059432,  0.00059439,  0.0005944 ],\n",
      "       [ 0.00020979,  0.00020982,  0.00020982],\n",
      "       [-0.00172014, -0.00172035, -0.00172036]]), array([ 0.12549263,  0.1237598 ,  0.124774  ,  0.125411  ,  0.12488142,\n",
      "       -0.12514902,  0.12466124,  0.12512428])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "deltas: [[ 0.00059432  0.00059439  0.0005944 ]\n",
      " [ 0.00020979  0.00020982  0.00020982]\n",
      " [-0.00172014 -0.00172035 -0.00172036]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.4943154  0.49856879 0.49962302]\n",
      "deltas: [ 0.12549263  0.1237598   0.124774    0.125411    0.12488142 -0.12514902\n",
      "  0.12466124  0.12512428]\n",
      "Partial of bias: [ 0.06203294  0.06117637  0.06167771  0.06199259  0.06173081 -0.06186309\n",
      "  0.06162197  0.06185086]\n",
      "[[ 0.00059432  0.          0.          0.          0.          0.\n",
      "   0.00059432  0.          0.        ]\n",
      " [ 0.00059439  0.          0.          0.          0.          0.\n",
      "   0.00059439  0.          0.        ]\n",
      " [ 0.0005944   0.          0.          0.          0.          0.\n",
      "   0.0005944   0.          0.        ]\n",
      " [ 0.00020979  0.          0.          0.          0.          0.\n",
      "   0.00020979  0.          0.        ]\n",
      " [ 0.00020982  0.          0.          0.          0.          0.\n",
      "   0.00020982  0.          0.        ]\n",
      " [ 0.00020982  0.          0.          0.          0.          0.\n",
      "   0.00020982  0.          0.        ]\n",
      " [-0.00172014 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.00172014 -0.         -0.        ]\n",
      " [-0.00172035 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.00172035 -0.         -0.        ]\n",
      " [-0.00172036 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.00172036 -0.         -0.        ]]\n",
      "mat_mul:  [-0.50199182 -0.49503416 -0.49911261 -0.50164748 -0.49952303 -0.49937281\n",
      "  0.50135956 -0.50050091] z:  [ 0.00796733 -0.01986402 -0.00354955  0.00658996 -0.0019079  -0.00250877\n",
      " -0.00543826  0.00200364]\n",
      "mat_mul:  [[-0.00117745]\n",
      " [-0.00500594]\n",
      " [-0.00135074]\n",
      " [ 0.00731649]] z:  [0.00974945 0.01181267 0.01088566]\n",
      "[array([[ 0.00125146,  0.00125144,  0.00125145],\n",
      "       [ 0.00033768,  0.00033767,  0.00033767],\n",
      "       [-0.00182908, -0.00182906, -0.00182907]]), array([ 0.12549596,  0.12374633,  0.12477776,  0.12541051,  0.12488064,\n",
      "        0.12484301, -0.12533896,  0.1251251 ])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "deltas: [[ 0.00125146  0.00125144  0.00125145]\n",
      " [ 0.00033768  0.00033767  0.00033767]\n",
      " [-0.00182908 -0.00182906 -0.00182907]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.50243734 0.50295313 0.50272139]\n",
      "deltas: [ 0.12549596  0.12374633  0.12477776  0.12541051  0.12488064  0.12484301\n",
      " -0.12533896  0.1251251 ]\n",
      "Partial of bias: [ 0.06305386  0.06217478  0.06269301  0.06301092  0.0627447   0.06272579\n",
      " -0.06297498  0.06286752]\n",
      "[[ 0.00125146  0.          0.          0.          0.          0.\n",
      "   0.          0.00125146  0.        ]\n",
      " [ 0.00125144  0.          0.          0.          0.          0.\n",
      "   0.          0.00125144  0.        ]\n",
      " [ 0.00125145  0.          0.          0.          0.          0.\n",
      "   0.          0.00125145  0.        ]\n",
      " [ 0.00033768  0.          0.          0.          0.          0.\n",
      "   0.          0.00033768  0.        ]\n",
      " [ 0.00033767  0.          0.          0.          0.          0.\n",
      "   0.          0.00033767  0.        ]\n",
      " [ 0.00033767  0.          0.          0.          0.          0.\n",
      "   0.          0.00033767  0.        ]\n",
      " [-0.00182908 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.00182908 -0.        ]\n",
      " [-0.00182906 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.00182906 -0.        ]\n",
      " [-0.00182907 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.00182907 -0.        ]]\n",
      "mat_mul:  [-0.50198526 -0.49506641 -0.49909951 -0.50165256 -0.49954109 -0.49938859\n",
      " -0.49863901  0.49950534] z:  [ 0.00794108 -0.01973501 -0.00360197  0.00661027 -0.00183562 -0.00244565\n",
      " -0.00544397  0.00197863]\n",
      "mat_mul:  [[-0.00098796]\n",
      " [-0.0047442 ]\n",
      " [-0.00144675]\n",
      " [ 0.0030729 ]] z:  [-0.01679819  0.00848484  0.00477333]\n",
      "[array([[ 0.00118597,  0.00118603,  0.00118604],\n",
      "       [ 0.00036166,  0.00036168,  0.00036168],\n",
      "       [-0.00076817, -0.00076821, -0.00076822]]), array([ 0.12549434,  0.12375455,  0.12477447,  0.12541177,  0.12488517,\n",
      "        0.12484696,  0.12465883, -0.12487621])]\n",
      "Layer 1: dimension deltas 2 (3, 3), dimension activations 1 (9,)\n",
      "activations: [1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "deltas: [[ 0.00118597  0.00118603  0.00118604]\n",
      " [ 0.00036166  0.00036168  0.00036168]\n",
      " [-0.00076817 -0.00076821 -0.00076822]]\n",
      "Partial of bias: [ 0.  0.  0.  0.  0.  0. -0. -0. -0.]\n",
      "Layer 2: dimension deltas 3 (8,), dimension activations 2 (4,)\n",
      "activations: [1.         0.49580055 0.5021212  0.50119333]\n",
      "deltas: [ 0.12549434  0.12375455  0.12477447  0.12541177  0.12488517  0.12484696\n",
      "  0.12465883 -0.12487621]\n",
      "Partial of bias: [ 0.06222016  0.06135758  0.06186325  0.06217922  0.06191814  0.06189919\n",
      "  0.06180592 -0.0619137 ]\n",
      "[[ 0.00118597  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00118597]\n",
      " [ 0.00118603  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00118603]\n",
      " [ 0.00118604  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00118604]\n",
      " [ 0.00036166  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00036166]\n",
      " [ 0.00036168  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00036168]\n",
      " [ 0.00036168  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.00036168]\n",
      " [-0.00076817 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.00076817]\n",
      " [-0.00076821 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.00076821]\n",
      " [-0.00076822 -0.         -0.         -0.         -0.         -0.\n",
      "  -0.         -0.         -0.00076822]]\n"
     ]
    }
   ],
   "source": [
    "# test_network.print_weights()\n",
    "# test_network.print_activations(X[0])\n",
    "# print(test_network.get_deltas(X[0], X[0]))\n",
    "for instance in X:\n",
    "    print(test_network.partial_derivatives(instance, instance, verbose=True)[0])\n",
    "# test_network.gradient_descent(X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75189953, 1.22339985, 1.22547545, 0.79885732, 0.91563999,\n",
       "       0.96365191, 0.97013856, 1.09595915])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(1,8)\n",
    "b = np.array([1,0,0,0,0,0,0,0])\n",
    "weights = np.random.rand(5,8)\n",
    "cost_function(quadratic_loss, a, b, weights, decay_parameter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([0,1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d06a35f6432bcea124c520d36814be75a6dd5ed4335e0c829924d510b7f0b7dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
